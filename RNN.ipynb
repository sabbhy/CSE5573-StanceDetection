{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HR_lLiVBDxW1",
        "hxo6RKCQ71dl",
        "kUAn5IOjEF8P",
        "dIfmW7vJ8Jx1",
        "9o91b6kKHjN4",
        "eoWQk0hO9bK2",
        "dB-g9F1TJOPx",
        "pfhjWZRD94hK",
        "S9ggYO6yHIm2",
        "axytMjGQmz6T"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Peyn-LR1q8zU",
        "outputId": "492658ad-9562-4261-9bf1-4db185a87ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN implementation: Partition df_train into train, val, test. \n",
        "4th cell under Split Data - we make the train dataset in the form \"parent_tweet_text -> tweet\"\n",
        "\n",
        "Number of epochs can be changed on the line right above the \"Evaluation\" section."
      ],
      "metadata": {
        "id": "q6M918EldxnQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQMVoxviKOz-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0j_RiUGAaYd",
        "outputId": "d1ec9dd0-2bcb-4a0c-fb7a-43c43cfc2bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev = pd.read_csv('/content/drive/Shareddrives/CSE 573 Semantic Web Mining/Annotated/dev1.csv')\n",
        "df_dev_body = pd.read_csv('/content/drive/Shareddrives/CSE 573 Semantic Web Mining/Annotated/dev_body1.csv')\n",
        "df_dev_stance = pd.read_csv('/content/drive/Shareddrives/CSE 573 Semantic Web Mining/Annotated/dev_stance1.csv')\n",
        "df_train = pd.read_csv('/content/drive/Shareddrives/CSE 573 Semantic Web Mining/Annotated/train1.csv')\n",
        "df_train_body = pd.read_csv('/content/drive/Shareddrives/CSE 573 Semantic Web Mining/Annotated/train_body1.csv')\n",
        "df_train_stance = pd.read_csv('/content/drive/Shareddrives/CSE 573 Semantic Web Mining/Annotated/train_stance1.csv')\n"
      ],
      "metadata": {
        "id": "ch_uCaSnoBAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN code"
      ],
      "metadata": {
        "id": "Bz-qkggDdh8K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V88LZeTqDePU"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlRv80v5DfdP",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoNhL0wTDgLW",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "SEED = 1234"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwVLi0UPDgOd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # multi-GPU# Set seeds for reproducibility\n",
        "set_seeds(seed=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK5Onfz9DiPO",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Set seeds for reproducibility\n",
        "set_seeds(seed=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T1rZDhsDiRt",
        "outputId": "93aaa26e-ae10-4d62-d489-b4c75bab95eb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device(\"cuda\" if (\n",
        "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
        "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "if device.type == \"cuda\":\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "print (device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c69z9wpJ56nE"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V_nEp5G58M0"
      },
      "source": [
        "We will download the [AG News dataset](http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html), which consists of 120K text samples from 4 unique classes (`Business`, `Sci/Tech`, `Sports`, `World`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3qKSoEe57na",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import urllib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BqaHCtToXWAb",
        "outputId": "6489a476-5619-4957-b979-a486034afc52",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                  id           parent_id  \\\n",
              "0        2409  500411534065950721  500410061974290433   \n",
              "1        1121  529716453792956416                None   \n",
              "2        2185  552803445711708160  552802654641225728   \n",
              "3        3247  524931144476028928  524925215235911680   \n",
              "4        1848  524953098201362432  524937542131793920   \n",
              "\n",
              "                                        parent_tweet  \\\n",
              "0  Not sure 'shoot first &amp; uncover potential ...   \n",
              "1                                                NaN   \n",
              "2  Charlie Hebdo shooting latest:  dead and gunme...   \n",
              "3  BREAKING news: Shots fired at Parliament Hill....   \n",
              "4  We are in full lock down until further notice ...   \n",
              "\n",
              "                                               tweet           topic  \\\n",
              "0  Early reports said the store had not reported ...        ferguson   \n",
              "1  Is Prince in Toronto? Rumours fly of surprise ...  prince-toronto   \n",
              "2  Dua belas. RT Charlie Hebdo shooting latest:  ...    charliehebdo   \n",
              "3  “globeandmail: BREAKING news: Shots fired at P...  ottawashooting   \n",
              "4  Stay safe my friends. RT We are in full lock d...  ottawashooting   \n",
              "\n",
              "  classification  \n",
              "0        comment  \n",
              "1        comment  \n",
              "2        support  \n",
              "3        comment  \n",
              "4        comment  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f23096de-173d-4c25-8ce8-0f974be3979f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>parent_tweet</th>\n",
              "      <th>tweet</th>\n",
              "      <th>topic</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2409</td>\n",
              "      <td>500411534065950721</td>\n",
              "      <td>500410061974290433</td>\n",
              "      <td>Not sure 'shoot first &amp;amp; uncover potential ...</td>\n",
              "      <td>Early reports said the store had not reported ...</td>\n",
              "      <td>ferguson</td>\n",
              "      <td>comment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1121</td>\n",
              "      <td>529716453792956416</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Is Prince in Toronto? Rumours fly of surprise ...</td>\n",
              "      <td>prince-toronto</td>\n",
              "      <td>comment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2185</td>\n",
              "      <td>552803445711708160</td>\n",
              "      <td>552802654641225728</td>\n",
              "      <td>Charlie Hebdo shooting latest:  dead and gunme...</td>\n",
              "      <td>Dua belas. RT Charlie Hebdo shooting latest:  ...</td>\n",
              "      <td>charliehebdo</td>\n",
              "      <td>support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3247</td>\n",
              "      <td>524931144476028928</td>\n",
              "      <td>524925215235911680</td>\n",
              "      <td>BREAKING news: Shots fired at Parliament Hill....</td>\n",
              "      <td>“globeandmail: BREAKING news: Shots fired at P...</td>\n",
              "      <td>ottawashooting</td>\n",
              "      <td>comment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1848</td>\n",
              "      <td>524953098201362432</td>\n",
              "      <td>524937542131793920</td>\n",
              "      <td>We are in full lock down until further notice ...</td>\n",
              "      <td>Stay safe my friends. RT We are in full lock d...</td>\n",
              "      <td>ottawashooting</td>\n",
              "      <td>comment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f23096de-173d-4c25-8ce8-0f974be3979f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f23096de-173d-4c25-8ce8-0f974be3979f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f23096de-173d-4c25-8ce8-0f974be3979f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Load data\n",
        "df = df_train\n",
        "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR_lLiVBDxW1"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u00AZ0O8DxaY"
      },
      "source": [
        "We're going to clean up our input data first by doing operations such as lower text, removing stop (filler) words, filters using regular expressions, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jq6a11YsDvEU",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5IpVaKqDvG1",
        "outputId": "55e4a3e3-d04a-4a6b-da1a-54e15ef44cb3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download(\"stopwords\")\n",
        "STOPWORDS = stopwords.words(\"english\")\n",
        "print (STOPWORDS[:5])\n",
        "porter = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n4w3KLQDvJk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def preprocess(text, stopwords=STOPWORDS):\n",
        "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "      return str(text)\n",
        "    # Lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n",
        "    text = pattern.sub('', text)\n",
        "\n",
        "    # Remove words in paranthesis\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric chars\n",
        "    text = re.sub(' +', ' ', text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "U9JmpiCmDvMz",
        "outputId": "ba6fc8ea-b0f6-41a7-f2a2-aa7e33c4d775",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Sample\n",
        "text = 0\n",
        "preprocess(text=text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RZ45-N9DvQD",
        "outputId": "1481ccad-53a8-48b4-eddf-00de4c11733e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       sure shoot first amp uncover potential crime l...\n",
              "1                                                     nan\n",
              "2       charlie hebdo shooting latest dead gunmen stil...\n",
              "3       breaking news shots fired parliament hill foll...\n",
              "4                          full lock notice ottawa police\n",
              "                              ...                        \n",
              "4233    police say shots fired ottawa sites national w...\n",
              "4234    tv channels chosen show videos hostages relayi...\n",
              "4235    breaking news soldier shot national war memori...\n",
              "4236    surveillance robbery release stills video ferg...\n",
              "4237    police confirm sydneysiege finally two people ...\n",
              "Name: parent_tweet, Length: 4238, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Apply to dataframe\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.parent_tweet = preprocessed_df.parent_tweet.apply(preprocess)\n",
        "preprocessed_df.tweet = preprocessed_df.tweet.apply(preprocess)\n",
        "\n",
        "# Test if it's working\n",
        "preprocessed_df.parent_tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxo6RKCQ71dl"
      },
      "source": [
        "## Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eS6kCcfY6IHE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qkWnO3uYPnk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "TRAIN_SIZE = 0.7\n",
        "VAL_SIZE = 0.15\n",
        "TEST_SIZE = 0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gbh2TLBXVDu",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def train_val_test_split(X, y, train_size):\n",
        "    \"\"\"Split dataset into data splits.\"\"\"\n",
        "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqiQd2j_76gP",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "X = (preprocessed_df[\"parent_tweet\"] + \" -> \"+ preprocessed_df[\"tweet\"]).values\n",
        "y = preprocessed_df[\"classification\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwdPM136EBMA",
        "outputId": "e0e89dc2-ef8a-4927-ed09-0d6f4b88ab94",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (2966,), y_train: (2966,)\n",
            "X_val: (636,), y_val: (636,)\n",
            "X_test: (636,), y_test: (636,)\n",
            "Sample point: black islamic flag held window lindt chocolate store martin place sydney hostages inside -> still sure motivation attack → query\n"
          ]
        }
      ],
      "source": [
        "# Create data splits\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
        "    X=X, y=y, train_size=TRAIN_SIZE)\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUAn5IOjEF8P"
      },
      "source": [
        "## LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNTjndI0EKzm"
      },
      "source": [
        "Next we'll define a `LabelEncoder` to encode our text labels into unique indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgLNA5yTELB1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeoPR77QELJT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class LabelEncoder(object):\n",
        "    \"\"\"Label encoder for tag labels.\"\"\"\n",
        "    def __init__(self, class_to_index={}):\n",
        "        self.class_to_index = class_to_index or {}  # mutable defaults ;)\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.class_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
        "\n",
        "    def fit(self, y):\n",
        "        classes = np.unique(y)\n",
        "        for i, class_ in enumerate(classes):\n",
        "            self.class_to_index[class_] = i\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "        return self\n",
        "\n",
        "    def encode(self, y):\n",
        "        encoded = np.zeros((len(y)), dtype=int)\n",
        "        for i, item in enumerate(y):\n",
        "            encoded[i] = self.class_to_index[item]\n",
        "        return encoded\n",
        "\n",
        "    def decode(self, y):\n",
        "        classes = []\n",
        "        for i, item in enumerate(y):\n",
        "            classes.append(self.index_to_class[item])\n",
        "        return classes\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, \"w\") as fp:\n",
        "            contents = {'class_to_index': self.class_to_index}\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MtTxMB5ELL4",
        "outputId": "a2a29b02-b1aa-4918-c061-ffa771e5e4cd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'comment': 0, 'deny': 1, 'query': 2, 'support': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Encode\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "NUM_CLASSES = len(label_encoder)\n",
        "label_encoder.class_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IzPFnoDELSr",
        "outputId": "37a9b6d4-e11b-4cea-efe4-cc487661abe4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train[0]: query\n",
            "y_train[0]: 2\n"
          ]
        }
      ],
      "source": [
        "# Convert labels to tokens\n",
        "print (f\"y_train[0]: {y_train[0]}\")\n",
        "y_train = label_encoder.encode(y_train)\n",
        "y_val = label_encoder.encode(y_val)\n",
        "y_test = label_encoder.encode(y_test)\n",
        "print (f\"y_train[0]: {y_train[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjESU2TOEQz_",
        "outputId": "cde9270a-8772-456a-bf63-250d47be6901",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts: [1913  233  231  589]\n",
            "weights: {0: 0.0005227391531625719, 1: 0.004291845493562232, 2: 0.004329004329004329, 3: 0.001697792869269949}\n"
          ]
        }
      ],
      "source": [
        "# Class weights\n",
        "counts = np.bincount(y_train)\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "print (f\"counts: {counts}\\nweights: {class_weights}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIfmW7vJ8Jx1"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYREXERdETdQ"
      },
      "source": [
        "We'll define a `Tokenizer` to convert our text input data into token indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0V6v1yeVGxNg",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from more_itertools import take"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChhTN8WDY4Z5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, char_level, num_tokens=None, \n",
        "                 pad_token='<PAD>', oov_token='<UNK>',\n",
        "                 token_to_index=None):\n",
        "        self.char_level = char_level\n",
        "        self.separator = '' if self.char_level else ' '\n",
        "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
        "        self.num_tokens = num_tokens\n",
        "        self.pad_token = pad_token\n",
        "        self.oov_token = oov_token\n",
        "        if not token_to_index:\n",
        "            token_to_index = {pad_token: 0, oov_token: 1}\n",
        "        self.token_to_index = token_to_index\n",
        "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        if not self.char_level:\n",
        "            texts = [text.split(\" \") for text in texts]\n",
        "        all_tokens = [token for text in texts for token in text]\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
        "        self.min_token_freq = counts[-1][1]\n",
        "        for token, count in counts:\n",
        "            index = len(self)\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "        return self\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            if not self.char_level:\n",
        "                text = text.split(' ')\n",
        "            sequence = []\n",
        "            for token in text:\n",
        "                sequence.append(self.token_to_index.get(\n",
        "                    token, self.token_to_index[self.oov_token]))\n",
        "            sequences.append(np.asarray(sequence))\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            text = []\n",
        "            for index in sequence:\n",
        "                text.append(self.index_to_token.get(index, self.oov_token))\n",
        "            texts.append(self.separator.join([token for token in text]))\n",
        "        return texts\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, \"w\") as fp:\n",
        "            contents = {\n",
        "                \"char_level\": self.char_level,\n",
        "                \"oov_token\": self.oov_token,\n",
        "                \"token_to_index\": self.token_to_index\n",
        "            }\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylpHSbcZYsXa",
        "outputId": "8c38a9e9-ac51-4220-a6ff-97d00608f401",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Tokenizer(num_tokens=5000)>\n"
          ]
        }
      ],
      "source": [
        "# Tokenize\n",
        "tokenizer = Tokenizer(char_level=False, num_tokens=5000)\n",
        "tokenizer.fit_on_texts(texts=X_train)\n",
        "VOCAB_SIZE = len(tokenizer)\n",
        "print (tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVgBSnFTfE5D",
        "outputId": "c7131459-5993-4b1a-f9fe-31fc387d9e9d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<PAD>', 0), ('<UNK>', 1), ('->', 2), ('police', 3), ('ferguson', 4)]\n",
            "least freq token's freq: 1\n"
          ]
        }
      ],
      "source": [
        "# Sample of tokens\n",
        "print (take(5, tokenizer.token_to_index.items()))\n",
        "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcscM_vL8KvP",
        "outputId": "a517c73c-78fb-4eaf-95ed-820c2b0f60f6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text to indices:\n",
            "  (preprocessed) → black islamic flag held window lindt chocolate store martin place sydney hostages inside -> still sure motivation attack\n",
            "  (tokenized) → [  75   76   33   32  121   97  727   55  175   70    5    9   58    2\n",
            "   38  185 3271   27]\n"
          ]
        }
      ],
      "source": [
        "# Convert texts to sequences of indices\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
        "print (\"Text to indices:\\n\"\n",
        "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
        "    f\"  (tokenized) → {X_train[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o91b6kKHjN4"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD6CuPxOHlsw"
      },
      "source": [
        "We'll need to do 2D padding to our tokenized text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcNEooUHHkwn",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        padded_sequences[i][:len(sequence)] = sequence\n",
        "    return padded_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfWHamHZHtT-",
        "outputId": "8ed54345-f3ac-4002-de45-a9396e5e5092",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 18)\n",
            "[[7.500e+01 7.600e+01 3.300e+01 3.200e+01 1.210e+02 9.700e+01 7.270e+02\n",
            "  5.500e+01 1.750e+02 7.000e+01 5.000e+00 9.000e+00 5.800e+01 2.000e+00\n",
            "  3.800e+01 1.850e+02 3.271e+03 2.700e+01]\n",
            " [1.500e+01 2.000e+00 2.560e+02 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            "  0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
            " [3.000e+00 1.076e+03 5.600e+01 1.560e+02 1.900e+01 7.300e+01 2.000e+02\n",
            "  4.900e+01 6.200e+01 2.300e+01 3.700e+01 2.000e+00 2.500e+01 8.800e+01\n",
            "  0.000e+00 0.000e+00 0.000e+00 0.000e+00]]\n"
          ]
        }
      ],
      "source": [
        "# 2D sequences\n",
        "padded = pad_sequences(X_train[0:3])\n",
        "print (padded.shape)\n",
        "print (padded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoWQk0hO9bK2"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSPbGwOkHvfj"
      },
      "source": [
        "We're going to create Datasets and DataLoaders to be able to efficiently create batches with our data splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSdfc0-cb9fc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y,):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        return [X, len(X), y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"Processing on a batch.\"\"\"\n",
        "        # Get inputs\n",
        "        batch = np.array(batch, dtype=object)\n",
        "        X = batch[:, 0]\n",
        "        seq_lens = batch[:, 1]\n",
        "        y = np.stack(batch[:, 2], axis=0)\n",
        "\n",
        "        # Pad inputs\n",
        "        X = pad_sequences(sequences=X)\n",
        "\n",
        "        # Cast\n",
        "        X = torch.LongTensor(X.astype(np.int32))\n",
        "        seq_lens = torch.LongTensor(seq_lens.astype(np.int32))\n",
        "        y = torch.LongTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, seq_lens, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
        "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYZtzbWMIXY7",
        "outputId": "b6e0112f-00eb-4d0c-f328-75f1b4ca3d89",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets:\n",
            "  Train dataset:<Dataset(N=2966)>\n",
            "  Val dataset: <Dataset(N=636)>\n",
            "  Test dataset: <Dataset(N=636)>\n",
            "Sample point:\n",
            "  X: [  75   76   33   32  121   97  727   55  175   70    5    9   58    2\n",
            "   38  185 3271   27]\n",
            "  seq_len: 18\n",
            "  y: 2\n"
          ]
        }
      ],
      "source": [
        "# Create datasets\n",
        "train_dataset = Dataset(X=X_train, y=y_train)\n",
        "val_dataset = Dataset(X=X_val, y=y_val)\n",
        "test_dataset = Dataset(X=X_test, y=y_test)\n",
        "print (\"Datasets:\\n\"\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {train_dataset[0][0]}\\n\"\n",
        "    f\"  seq_len: {train_dataset[0][1]}\\n\"\n",
        "    f\"  y: {train_dataset[0][2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w6wVKJe9fxk",
        "outputId": "aa2dbf15-7b07-4deb-a9dd-327e4a66ffc1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample batch:\n",
            "  X: [64, 30]\n",
            "  seq_lens: [64]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([  75,   76,   33,   32,  121,   97,  727,   55,  175,   70,    5,    9,\n",
            "          58,    2,   38,  185, 3271,   27,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0])\n",
            " seq_len: 18\n",
            "  y: 2\n"
          ]
        }
      ],
      "source": [
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_dataloader = train_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "batch_X, batch_seq_lens, batch_y = next(iter(train_dataloader))\n",
        "print (\"Sample batch:\\n\"\n",
        "    f\"  X: {list(batch_X.size())}\\n\"\n",
        "    f\"  seq_lens: {list(batch_seq_lens.size())}\\n\"\n",
        "    f\"  y: {list(batch_y.size())}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {batch_X[0]}\\n\"\n",
        "    f\" seq_len: {batch_seq_lens[0]}\\n\"\n",
        "    f\"  y: {batch_y[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB-g9F1TJOPx"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL5FcX0hJR37"
      },
      "source": [
        "Let's create the `Trainer` class that we'll use to facilitate training for our experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5KWF-DXJN2a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]  # Set device\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.inference_mode():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = F.softmax(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.inference_mode():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = F.softmax(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "    \n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "        return best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUMibnFtuq_i"
      },
      "source": [
        "# Vanilla RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwyHfs4JvC7F"
      },
      "source": [
        "Inputs to RNNs are sequential like text or time-series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3e6DbkwhXow",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOs64ORxvBei",
        "outputId": "3d66050a-37ec-4db6-969f-a648a7085393",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 8, 100])\n",
            "torch.Size([1, 64])\n"
          ]
        }
      ],
      "source": [
        "# Input\n",
        "sequence_size = 8 # words per input\n",
        "x = torch.rand((BATCH_SIZE, sequence_size, EMBEDDING_DIM))\n",
        "seq_lens = torch.randint(high=sequence_size, size=(1, BATCH_SIZE))\n",
        "print (x.shape)\n",
        "print (seq_lens.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-Eb1HdRhnmu",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "RNN_HIDDEN_DIM = 128\n",
        "DROPOUT_P = 0.1\n",
        "RNN_DROPOUT_P = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJmu7XUTsc3F",
        "outputId": "1faca73a-4019-41f1-d33d-19786162f7b2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 128])\n"
          ]
        }
      ],
      "source": [
        "# Initialize hidden state\n",
        "hidden_t = torch.zeros((BATCH_SIZE, RNN_HIDDEN_DIM))\n",
        "print (hidden_t.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-O2Du78ut8J",
        "outputId": "7ae2f562-d16b-4d98-a15b-625dfe3d56fb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNNCell(100, 128)\n"
          ]
        }
      ],
      "source": [
        "# Initialize RNN cell\n",
        "rnn_cell = nn.RNNCell(EMBEDDING_DIM, RNN_HIDDEN_DIM)\n",
        "print (rnn_cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqOtTdDx3Nz7",
        "outputId": "62e032e7-5062-42de-9f64-2a6863411dbd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 8, 128])\n"
          ]
        }
      ],
      "source": [
        "# Forward pass through RNN\n",
        "x = x.permute(1, 0, 2) # RNN needs batch_size to be at dim 1\n",
        "\n",
        "# Loop through the inputs time steps\n",
        "hiddens = []\n",
        "for t in range(sequence_size):\n",
        "    hidden_t = rnn_cell(x[t], hidden_t)\n",
        "    hiddens.append(hidden_t)\n",
        "hiddens = torch.stack(hiddens)\n",
        "hiddens = hiddens.permute(1, 0, 2) # bring batch_size back to dim 0\n",
        "print (hiddens.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1rb4lsltO-c",
        "outputId": "5a077ff8-25fe-469b-cb7d-b45376b4de59",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out:  torch.Size([64, 8, 128])\n",
            "h_n:  torch.Size([1, 64, 128])\n"
          ]
        }
      ],
      "source": [
        "# We also could've used a more abstracted layer\n",
        "x = torch.rand((BATCH_SIZE, sequence_size, EMBEDDING_DIM))\n",
        "rnn = nn.RNN(EMBEDDING_DIM, RNN_HIDDEN_DIM, batch_first=True)\n",
        "out, h_n = rnn(x) # h_n is the last hidden state\n",
        "print (\"out: \", out.shape)\n",
        "print (\"h_n: \", h_n.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYoA2Wbet9wr",
        "outputId": "7d7944df-2cf6-41c7-b4fd-f648f316b756",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0359, -0.3819,  0.2162,  ..., -0.3397,  0.0468,  0.1937],\n",
            "        [-0.4914, -0.3056, -0.0837,  ..., -0.3507, -0.4320,  0.3593],\n",
            "        [-0.0989, -0.2852,  0.1170,  ..., -0.0805, -0.0786,  0.3922],\n",
            "        ...,\n",
            "        [-0.3115, -0.4169,  0.2611,  ..., -0.3214,  0.0620,  0.0338],\n",
            "        [-0.2455, -0.3380,  0.2048,  ..., -0.4198, -0.0075,  0.0372],\n",
            "        [-0.2092, -0.4594,  0.1654,  ..., -0.5397, -0.1709,  0.0023]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "tensor([[-0.0359, -0.3819,  0.2162,  ..., -0.3397,  0.0468,  0.1937],\n",
            "        [-0.4914, -0.3056, -0.0837,  ..., -0.3507, -0.4320,  0.3593],\n",
            "        [-0.0989, -0.2852,  0.1170,  ..., -0.0805, -0.0786,  0.3922],\n",
            "        ...,\n",
            "        [-0.3115, -0.4169,  0.2611,  ..., -0.3214,  0.0620,  0.0338],\n",
            "        [-0.2455, -0.3380,  0.2048,  ..., -0.4198, -0.0075,  0.0372],\n",
            "        [-0.2092, -0.4594,  0.1654,  ..., -0.5397, -0.1709,  0.0023]],\n",
            "       grad_fn=<SqueezeBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# The same tensors\n",
        "print (out[:,-1,:])\n",
        "print (h_n.squeeze(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WJ_ZqzAu6Uk"
      },
      "source": [
        "In our model, we want to use the RNN's output after the last relevant token in the sentence is processed. The last relevant token doesn't refer the `<PAD>` tokens but to the last actual word in the sentence and its index is different for each input in the batch. This is why we included a `seq_lens` tensor in our batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqPOY6qbu6e0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def gather_last_relevant_hidden(hiddens, seq_lens):\n",
        "    \"\"\"Extract and collect the last relevant \n",
        "    hidden state based on the sequence length.\"\"\"\n",
        "    seq_lens = seq_lens.long().detach().cpu().numpy() - 1\n",
        "    out = []\n",
        "    for batch_index, column_index in enumerate(seq_lens):\n",
        "        out.append(hiddens[batch_index, column_index])\n",
        "    return torch.stack(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDIwDHJOu7Kj",
        "outputId": "b5a026fb-2a68-4458-9335-24a3ef3ee0d7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Get the last relevant hidden state\n",
        "gather_last_relevant_hidden(hiddens=out, seq_lens=seq_lens).squeeze(0).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfhjWZRD94hK"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXDA4UNdxmZT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoBC0u8XpbVv",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "HIDDEN_DIM = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPP5ROd69mXC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, rnn_hidden_dim,\n",
        "                 hidden_dim, dropout_p, num_classes, padding_idx=0):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        # Initialize embeddings\n",
        "        self.embeddings = nn.Embedding(\n",
        "            embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "            padding_idx=padding_idx)\n",
        "        \n",
        "        # RNN\n",
        "        self.rnn = nn.RNN(embedding_dim, rnn_hidden_dim, batch_first=True)\n",
        "     \n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(rnn_hidden_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Embed\n",
        "        x_in, seq_lens = inputs\n",
        "        x_in = self.embeddings(x_in)\n",
        "            \n",
        "        # Rnn outputs\n",
        "        out, h_n = self.rnn(x_in)\n",
        "        z = gather_last_relevant_hidden(hiddens=out, seq_lens=seq_lens)\n",
        "\n",
        "        # FC layers\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        z = self.fc2(z)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH_z2FqUn5DR",
        "outputId": "3c45de29-e6b5-4a50-b017-89c65dd1bd3a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.named_parameters of RNN(\n",
            "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
            "  (rnn): RNN(100, 128, batch_first=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=128, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ]
        }
      ],
      "source": [
        "# Simple RNN cell\n",
        "model = RNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE, \n",
        "    rnn_hidden_dim=RNN_HIDDEN_DIM, hidden_dim=HIDDEN_DIM, \n",
        "    dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9ggYO6yHIm2"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geKOPVzVK6S9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfSBvenCiIce",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "NUM_LAYERS = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "PATIENCE = 50\n",
        "NUM_EPOCHS = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ilmlIMUzNIj",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ucn3tYq1_sE1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE) \n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.1, patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5ac-uJXb-F7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn, \n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-uKcZrABKVZ",
        "outputId": "0a97de24-a623-44fb-de8a-4f3986705d5e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 1.39516, val_loss: 1.39864, lr: 1.00E-04, _patience: 50\n",
            "Epoch: 2 | train_loss: 1.37513, val_loss: 1.39239, lr: 1.00E-04, _patience: 50\n",
            "Epoch: 3 | train_loss: 1.36242, val_loss: 1.38752, lr: 1.00E-04, _patience: 50\n",
            "Epoch: 4 | train_loss: 1.34279, val_loss: 1.38350, lr: 1.00E-04, _patience: 50\n",
            "Epoch: 5 | train_loss: 1.32747, val_loss: 1.37985, lr: 1.00E-04, _patience: 50\n",
            "Epoch: 6 | train_loss: 1.31053, val_loss: 1.37653, lr: 1.00E-04, _patience: 50\n",
            "Epoch: 7 | train_loss: 1.28917, val_loss: 1.37359, lr: 1.00E-04, _patience: 50\n",
            "Epoch: 8 | train_loss: 1.26294, val_loss: 1.37171, lr: 1.00E-04, _patience: 50\n",
            "Epoch: 9 | train_loss: 1.23258, val_loss: 1.37234, lr: 1.00E-04, _patience: 49\n",
            "Epoch: 10 | train_loss: 1.20050, val_loss: 1.37794, lr: 1.00E-04, _patience: 48\n",
            "Epoch: 11 | train_loss: 1.16603, val_loss: 1.38896, lr: 1.00E-04, _patience: 47\n",
            "Epoch: 12 | train_loss: 1.13184, val_loss: 1.40334, lr: 1.00E-05, _patience: 46\n",
            "Epoch: 13 | train_loss: 1.10126, val_loss: 1.40518, lr: 1.00E-05, _patience: 45\n",
            "Epoch: 14 | train_loss: 1.09546, val_loss: 1.40702, lr: 1.00E-05, _patience: 44\n",
            "Epoch: 15 | train_loss: 1.09283, val_loss: 1.40887, lr: 1.00E-05, _patience: 43\n",
            "Epoch: 16 | train_loss: 1.09149, val_loss: 1.41067, lr: 1.00E-06, _patience: 42\n",
            "Epoch: 17 | train_loss: 1.08476, val_loss: 1.41086, lr: 1.00E-06, _patience: 41\n",
            "Epoch: 18 | train_loss: 1.08706, val_loss: 1.41105, lr: 1.00E-06, _patience: 40\n",
            "Epoch: 19 | train_loss: 1.08690, val_loss: 1.41123, lr: 1.00E-06, _patience: 39\n",
            "Epoch: 20 | train_loss: 1.08704, val_loss: 1.41141, lr: 1.00E-07, _patience: 38\n",
            "Epoch: 21 | train_loss: 1.08383, val_loss: 1.41143, lr: 1.00E-07, _patience: 37\n",
            "Epoch: 22 | train_loss: 1.08671, val_loss: 1.41144, lr: 1.00E-07, _patience: 36\n",
            "Epoch: 23 | train_loss: 1.08450, val_loss: 1.41146, lr: 1.00E-07, _patience: 35\n",
            "Epoch: 24 | train_loss: 1.08391, val_loss: 1.41148, lr: 1.00E-08, _patience: 34\n",
            "Epoch: 25 | train_loss: 1.08208, val_loss: 1.41148, lr: 1.00E-08, _patience: 33\n",
            "Epoch: 26 | train_loss: 1.08831, val_loss: 1.41148, lr: 1.00E-08, _patience: 32\n",
            "Epoch: 27 | train_loss: 1.08395, val_loss: 1.41148, lr: 1.00E-08, _patience: 31\n",
            "Epoch: 28 | train_loss: 1.08665, val_loss: 1.41148, lr: 1.00E-08, _patience: 30\n",
            "Epoch: 29 | train_loss: 1.08708, val_loss: 1.41149, lr: 1.00E-08, _patience: 29\n",
            "Epoch: 30 | train_loss: 1.08537, val_loss: 1.41149, lr: 1.00E-08, _patience: 28\n",
            "Epoch: 31 | train_loss: 1.08661, val_loss: 1.41149, lr: 1.00E-08, _patience: 27\n",
            "Epoch: 32 | train_loss: 1.08474, val_loss: 1.41149, lr: 1.00E-08, _patience: 26\n",
            "Epoch: 33 | train_loss: 1.08431, val_loss: 1.41149, lr: 1.00E-08, _patience: 25\n",
            "Epoch: 34 | train_loss: 1.08143, val_loss: 1.41149, lr: 1.00E-08, _patience: 24\n",
            "Epoch: 35 | train_loss: 1.08151, val_loss: 1.41150, lr: 1.00E-08, _patience: 23\n",
            "Epoch: 36 | train_loss: 1.08358, val_loss: 1.41150, lr: 1.00E-08, _patience: 22\n",
            "Epoch: 37 | train_loss: 1.08538, val_loss: 1.41150, lr: 1.00E-08, _patience: 21\n",
            "Epoch: 38 | train_loss: 1.08344, val_loss: 1.41150, lr: 1.00E-08, _patience: 20\n",
            "Epoch: 39 | train_loss: 1.08492, val_loss: 1.41150, lr: 1.00E-08, _patience: 19\n",
            "Epoch: 40 | train_loss: 1.08683, val_loss: 1.41150, lr: 1.00E-08, _patience: 18\n",
            "Epoch: 41 | train_loss: 1.08679, val_loss: 1.41151, lr: 1.00E-08, _patience: 17\n",
            "Epoch: 42 | train_loss: 1.08311, val_loss: 1.41151, lr: 1.00E-08, _patience: 16\n",
            "Epoch: 43 | train_loss: 1.08423, val_loss: 1.41151, lr: 1.00E-08, _patience: 15\n",
            "Epoch: 44 | train_loss: 1.08431, val_loss: 1.41151, lr: 1.00E-08, _patience: 14\n",
            "Epoch: 45 | train_loss: 1.08607, val_loss: 1.41151, lr: 1.00E-08, _patience: 13\n",
            "Epoch: 46 | train_loss: 1.08485, val_loss: 1.41151, lr: 1.00E-08, _patience: 12\n",
            "Epoch: 47 | train_loss: 1.08475, val_loss: 1.41152, lr: 1.00E-08, _patience: 11\n",
            "Epoch: 48 | train_loss: 1.08679, val_loss: 1.41152, lr: 1.00E-08, _patience: 10\n",
            "Epoch: 49 | train_loss: 1.08395, val_loss: 1.41152, lr: 1.00E-08, _patience: 9\n",
            "Epoch: 50 | train_loss: 1.08388, val_loss: 1.41152, lr: 1.00E-08, _patience: 8\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axytMjGQmz6T"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ly3zjVAm4Wr",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojOfz9rjm4ZI",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def get_performance(y_true, y_pred, classes):\n",
        "    \"\"\"Per-class performance metrics.\"\"\"\n",
        "    # Performance\n",
        "    performance = {\"overall\": {}, \"class\": {}}\n",
        "\n",
        "    # Overall performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
        "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
        "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
        "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
        "    performance[\"overall\"][\"accuracy\"] = accuracy_score(y_true, y_pred)\n",
        "   \n",
        "    # Per-class performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "    for i in range(len(classes)):\n",
        "        performance[\"class\"][classes[i]] = {\n",
        "            \"precision\": metrics[0][i],\n",
        "            \"recall\": metrics[1][i],\n",
        "            \"f1\": metrics[2][i],\n",
        "            \"num_samples\": np.float64(metrics[3][i]),\n",
        "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        }\n",
        "\n",
        "    return performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tho3e_yQzqZ1",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "64b83d80-c526-4b83-8d81-1803512223d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fylHduxTK-0N",
        "outputId": "3ebdf5d4-7039-4ed8-995e-ebe1bf24569a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"precision\": 0.5073093558255758,\n",
            "  \"recall\": 0.27672955974842767,\n",
            "  \"f1\": 0.2957695789042687,\n",
            "  \"num_samples\": 636.0,\n",
            "  \"accuracy\": 0.27672955974842767\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Determine performance\n",
        "performance = get_performance(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance[\"overall\"], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "diF-oMIYEwpS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}